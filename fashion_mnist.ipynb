{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "wJImnLRvS10E"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zachhom/170-P3-Neural-Net/blob/Haneul/fashion_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Writeup\n",
        "\n",
        "For the writeup, please include the following information:\n",
        "\n",
        "\n",
        "*   Describe the architecture of your neural network\n",
        "*   Discuss how you tuned your network and why you think it's performance is reasonable for this task\n",
        "*   Discuss whether or not you feel that this classifier is appropriate for the given task (check PA3 description)\n",
        "\n"
      ],
      "metadata": {
        "id": "qxOhrr4P1jWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch"
      ],
      "metadata": {
        "id": "wJImnLRvS10E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0 Imports"
      ],
      "metadata": {
        "id": "9Oj-THYrHY-F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJF_htAsHP18"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Set Hyperparameters"
      ],
      "metadata": {
        "id": "o7QPmU2THeE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You can modify these values\n",
        "\n",
        "n_epochs = 3\n",
        "batch_size_train = 64\n",
        "batch_size_test = 1000\n",
        "learning_rate = 0.01\n",
        "momentum = 0.5\n",
        "log_interval = 100"
      ],
      "metadata": {
        "id": "Q2jvrRp6Hdhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load Data"
      ],
      "metadata": {
        "id": "5BF4XieJH6r8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = torchvision.datasets.FashionMNIST(\n",
        "  root = './data/FashionMNIST',\n",
        "  train = True,\n",
        "  download = True,\n",
        "  transform = transforms.Compose([\n",
        "      transforms.ToTensor()                                 \n",
        "  ]))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set,\n",
        "                                     batch_size = batch_size_train,\n",
        "                                     shuffle=True)\n",
        "\n",
        "train_set = torchvision.datasets.FashionMNIST(\n",
        "  root = './data/FashionMNIST',\n",
        "  train = False,\n",
        "  download = True,\n",
        "  transform = transforms.Compose([\n",
        "      transforms.ToTensor()                                 \n",
        "  ]))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(train_set,\n",
        "                                     batch_size = batch_size_train,\n",
        "                                     shuffle=True)"
      ],
      "metadata": {
        "id": "9ksSnoOcH_2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = enumerate(test_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "leynP5FNILE6",
        "outputId": "7f5bbe0f-c1f9-45b0-db8d-272f231e0219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_CHANNELS = example_data.shape[1]\n",
        "OUTPUT_CLASSES = 10\n",
        "example_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SVbsV3JJOyN",
        "outputId": "f7a92d66-3111-4a12-8787-88ea61ca5c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Define Model"
      ],
      "metadata": {
        "id": "jd448qcTI08A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(INPUT_SHAPE, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 32)\n",
        "        self.fc4 = nn.Linear(32, OUTPUT_CLASSES)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.fc4(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "FPJ3fN3IIubV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net().to(device)\n",
        "net"
      ],
      "metadata": {
        "id": "cMoEjiakOJ0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Train Model"
      ],
      "metadata": {
        "id": "HtfpbeNoKA-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "train_counter = []\n",
        "test_losses = []\n",
        "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "U3PqYa_JKW5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "SdQxhR9LKAWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, n_epochs + 1):\n",
        "  train(net, train_loader, optimizer, epoch)\n",
        "  test(net, test_loader)"
      ],
      "metadata": {
        "id": "cO6SfXSkKbIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorflow"
      ],
      "metadata": {
        "id": "4XcY-TlhGxru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Imports"
      ],
      "metadata": {
        "id": "KyU1ThEPG0Mx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout"
      ],
      "metadata": {
        "id": "0F1QY_IOG2e1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Set Hyperparameters"
      ],
      "metadata": {
        "id": "qJe1xk4QHEvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tune these\n",
        "\n",
        "n_epochs = 50\n",
        "batch_size_train = 2500\n",
        "batch_size_test = 10000\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "tsXzcHqDHTku"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Import Data"
      ],
      "metadata": {
        "id": "n13sUlF_HJ1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'fashion_mnist',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "def normalize_img(image, label):\n",
        "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
        "  return tf.cast(image, tf.float32) / 255., label\n",
        "\n",
        "ds_train = ds_train.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_train = ds_train.cache()\n",
        "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
        "ds_train = ds_train.batch(batch_size_train)\n",
        "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "ds_test = ds_test.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_test = ds_test.batch(batch_size_test)\n",
        "ds_test = ds_test.cache()\n",
        "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "W4uIM9TaHWUH"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Define Model"
      ],
      "metadata": {
        "id": "DgEqnLBsR3W6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Convolutional Layers\n",
        "# model.add(tf.keras.layers.Conv2D(20, (2,2), padding='same', activation='relu', input_shape=(28,28,1)))\n",
        "# model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "# model.add(tf.keras.layers.Conv2D(40, (2,2), padding='same', activation='relu'))\n",
        "# model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Dense Layers\n",
        "# model.add(tf.keras.layers.Flatten())\n",
        "# model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "# model.add(tf.keras.layers.Dense(16, activation='relu')) #256\n",
        "# model.add(tf.keras.layers.Dense(126, activation='relu'))\n",
        "# model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "v4wX6lQOHjeK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b9ba6cb-e1f4-4ee0-9eee-8a0a2b83d010"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_20 (Conv2D)          (None, 28, 28, 64)        320       \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 14, 14, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 14, 14, 32)        8224      \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 7, 7, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 7, 7, 32)          0         \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 1568)              0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 256)               401664    \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 412,778\n",
            "Trainable params: 412,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Things to consider:\n",
        "\n",
        "* dropout, convensation, things like that\n",
        "* overtrain\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "es5iz2n7jGpe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LRVf9D0mjGel"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Train Model"
      ],
      "metadata": {
        "id": "f5VZLjUSHNl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    ds_train,\n",
        "    epochs=n_epochs,\n",
        "    validation_data=ds_test,\n",
        ")\n"
      ],
      "metadata": {
        "id": "GQp_7VQtHwXi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6934f26-6249-46ef-8178-fdfcce825a3c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "24/24 [==============================] - 8s 113ms/step - loss: 0.9823 - sparse_categorical_accuracy: 0.6411 - val_loss: 0.5197 - val_sparse_categorical_accuracy: 0.8127\n",
            "Epoch 2/50\n",
            "24/24 [==============================] - 2s 83ms/step - loss: 0.4723 - sparse_categorical_accuracy: 0.8283 - val_loss: 0.3855 - val_sparse_categorical_accuracy: 0.8621\n",
            "Epoch 3/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.3906 - sparse_categorical_accuracy: 0.8575 - val_loss: 0.3355 - val_sparse_categorical_accuracy: 0.8800\n",
            "Epoch 4/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.3539 - sparse_categorical_accuracy: 0.8709 - val_loss: 0.3196 - val_sparse_categorical_accuracy: 0.8863\n",
            "Epoch 5/50\n",
            "24/24 [==============================] - 2s 80ms/step - loss: 0.3314 - sparse_categorical_accuracy: 0.8793 - val_loss: 0.2937 - val_sparse_categorical_accuracy: 0.8928\n",
            "Epoch 6/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.3117 - sparse_categorical_accuracy: 0.8861 - val_loss: 0.2869 - val_sparse_categorical_accuracy: 0.8951\n",
            "Epoch 7/50\n",
            "24/24 [==============================] - 2s 82ms/step - loss: 0.2994 - sparse_categorical_accuracy: 0.8896 - val_loss: 0.2742 - val_sparse_categorical_accuracy: 0.8996\n",
            "Epoch 8/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.2867 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.2693 - val_sparse_categorical_accuracy: 0.9025\n",
            "Epoch 9/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.2826 - sparse_categorical_accuracy: 0.8958 - val_loss: 0.2574 - val_sparse_categorical_accuracy: 0.9055\n",
            "Epoch 10/50\n",
            "24/24 [==============================] - 2s 82ms/step - loss: 0.2720 - sparse_categorical_accuracy: 0.8991 - val_loss: 0.2622 - val_sparse_categorical_accuracy: 0.9041\n",
            "Epoch 11/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.2615 - sparse_categorical_accuracy: 0.9031 - val_loss: 0.2580 - val_sparse_categorical_accuracy: 0.9031\n",
            "Epoch 12/50\n",
            "24/24 [==============================] - 2s 82ms/step - loss: 0.2560 - sparse_categorical_accuracy: 0.9053 - val_loss: 0.2426 - val_sparse_categorical_accuracy: 0.9106\n",
            "Epoch 13/50\n",
            "24/24 [==============================] - 2s 82ms/step - loss: 0.2471 - sparse_categorical_accuracy: 0.9081 - val_loss: 0.2397 - val_sparse_categorical_accuracy: 0.9147\n",
            "Epoch 14/50\n",
            "24/24 [==============================] - 2s 82ms/step - loss: 0.2459 - sparse_categorical_accuracy: 0.9083 - val_loss: 0.2343 - val_sparse_categorical_accuracy: 0.9130\n",
            "Epoch 15/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.2384 - sparse_categorical_accuracy: 0.9110 - val_loss: 0.2349 - val_sparse_categorical_accuracy: 0.9140\n",
            "Epoch 16/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.2352 - sparse_categorical_accuracy: 0.9123 - val_loss: 0.2304 - val_sparse_categorical_accuracy: 0.9181\n",
            "Epoch 17/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.2299 - sparse_categorical_accuracy: 0.9151 - val_loss: 0.2336 - val_sparse_categorical_accuracy: 0.9127\n",
            "Epoch 18/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.2311 - sparse_categorical_accuracy: 0.9129 - val_loss: 0.2457 - val_sparse_categorical_accuracy: 0.9120\n",
            "Epoch 19/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.2292 - sparse_categorical_accuracy: 0.9139 - val_loss: 0.2344 - val_sparse_categorical_accuracy: 0.9168\n",
            "Epoch 20/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.2238 - sparse_categorical_accuracy: 0.9168 - val_loss: 0.2311 - val_sparse_categorical_accuracy: 0.9168\n",
            "Epoch 21/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.2202 - sparse_categorical_accuracy: 0.9184 - val_loss: 0.2333 - val_sparse_categorical_accuracy: 0.9126\n",
            "Epoch 22/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.2149 - sparse_categorical_accuracy: 0.9197 - val_loss: 0.2222 - val_sparse_categorical_accuracy: 0.9214\n",
            "Epoch 23/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.2074 - sparse_categorical_accuracy: 0.9226 - val_loss: 0.2224 - val_sparse_categorical_accuracy: 0.9209\n",
            "Epoch 24/50\n",
            "24/24 [==============================] - 2s 80ms/step - loss: 0.2067 - sparse_categorical_accuracy: 0.9226 - val_loss: 0.2174 - val_sparse_categorical_accuracy: 0.9215\n",
            "Epoch 25/50\n",
            "24/24 [==============================] - 2s 80ms/step - loss: 0.2023 - sparse_categorical_accuracy: 0.9243 - val_loss: 0.2192 - val_sparse_categorical_accuracy: 0.9199\n",
            "Epoch 26/50\n",
            "24/24 [==============================] - 2s 80ms/step - loss: 0.2016 - sparse_categorical_accuracy: 0.9242 - val_loss: 0.2244 - val_sparse_categorical_accuracy: 0.9195\n",
            "Epoch 27/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.2023 - sparse_categorical_accuracy: 0.9236 - val_loss: 0.2299 - val_sparse_categorical_accuracy: 0.9172\n",
            "Epoch 28/50\n",
            "24/24 [==============================] - 2s 80ms/step - loss: 0.2004 - sparse_categorical_accuracy: 0.9247 - val_loss: 0.2181 - val_sparse_categorical_accuracy: 0.9211\n",
            "Epoch 29/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.1957 - sparse_categorical_accuracy: 0.9263 - val_loss: 0.2130 - val_sparse_categorical_accuracy: 0.9220\n",
            "Epoch 30/50\n",
            "24/24 [==============================] - 2s 80ms/step - loss: 0.1948 - sparse_categorical_accuracy: 0.9267 - val_loss: 0.2132 - val_sparse_categorical_accuracy: 0.9242\n",
            "Epoch 31/50\n",
            "24/24 [==============================] - 2s 79ms/step - loss: 0.1908 - sparse_categorical_accuracy: 0.9274 - val_loss: 0.2133 - val_sparse_categorical_accuracy: 0.9245\n",
            "Epoch 32/50\n",
            "24/24 [==============================] - 2s 79ms/step - loss: 0.1945 - sparse_categorical_accuracy: 0.9268 - val_loss: 0.2207 - val_sparse_categorical_accuracy: 0.9205\n",
            "Epoch 33/50\n",
            "24/24 [==============================] - 2s 80ms/step - loss: 0.1904 - sparse_categorical_accuracy: 0.9282 - val_loss: 0.2140 - val_sparse_categorical_accuracy: 0.9253\n",
            "Epoch 34/50\n",
            "24/24 [==============================] - 2s 80ms/step - loss: 0.1912 - sparse_categorical_accuracy: 0.9280 - val_loss: 0.2530 - val_sparse_categorical_accuracy: 0.9104\n",
            "Epoch 35/50\n",
            "24/24 [==============================] - 2s 80ms/step - loss: 0.1931 - sparse_categorical_accuracy: 0.9258 - val_loss: 0.2234 - val_sparse_categorical_accuracy: 0.9205\n",
            "Epoch 36/50\n",
            "24/24 [==============================] - 2s 80ms/step - loss: 0.1863 - sparse_categorical_accuracy: 0.9300 - val_loss: 0.2221 - val_sparse_categorical_accuracy: 0.9213\n",
            "Epoch 37/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.1896 - sparse_categorical_accuracy: 0.9266 - val_loss: 0.2219 - val_sparse_categorical_accuracy: 0.9226\n",
            "Epoch 38/50\n",
            "24/24 [==============================] - 2s 80ms/step - loss: 0.1793 - sparse_categorical_accuracy: 0.9312 - val_loss: 0.2230 - val_sparse_categorical_accuracy: 0.9228\n",
            "Epoch 39/50\n",
            "24/24 [==============================] - 2s 80ms/step - loss: 0.1801 - sparse_categorical_accuracy: 0.9324 - val_loss: 0.2185 - val_sparse_categorical_accuracy: 0.9217\n",
            "Epoch 40/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.1768 - sparse_categorical_accuracy: 0.9328 - val_loss: 0.2223 - val_sparse_categorical_accuracy: 0.9214\n",
            "Epoch 41/50\n",
            "24/24 [==============================] - 2s 80ms/step - loss: 0.1825 - sparse_categorical_accuracy: 0.9284 - val_loss: 0.2269 - val_sparse_categorical_accuracy: 0.9210\n",
            "Epoch 42/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.1784 - sparse_categorical_accuracy: 0.9328 - val_loss: 0.2159 - val_sparse_categorical_accuracy: 0.9248\n",
            "Epoch 43/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.1729 - sparse_categorical_accuracy: 0.9352 - val_loss: 0.2171 - val_sparse_categorical_accuracy: 0.9252\n",
            "Epoch 44/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.1750 - sparse_categorical_accuracy: 0.9335 - val_loss: 0.2225 - val_sparse_categorical_accuracy: 0.9201\n",
            "Epoch 45/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.1738 - sparse_categorical_accuracy: 0.9347 - val_loss: 0.2239 - val_sparse_categorical_accuracy: 0.9223\n",
            "Epoch 46/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.1750 - sparse_categorical_accuracy: 0.9325 - val_loss: 0.2262 - val_sparse_categorical_accuracy: 0.9212\n",
            "Epoch 47/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.1705 - sparse_categorical_accuracy: 0.9350 - val_loss: 0.2134 - val_sparse_categorical_accuracy: 0.9271\n",
            "Epoch 48/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.1666 - sparse_categorical_accuracy: 0.9373 - val_loss: 0.2178 - val_sparse_categorical_accuracy: 0.9251\n",
            "Epoch 49/50\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.1694 - sparse_categorical_accuracy: 0.9355 - val_loss: 0.2277 - val_sparse_categorical_accuracy: 0.9219\n",
            "Epoch 50/50\n",
            "24/24 [==============================] - 2s 80ms/step - loss: 0.1691 - sparse_categorical_accuracy: 0.9356 - val_loss: 0.2235 - val_sparse_categorical_accuracy: 0.9223\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f672e0a6c10>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}